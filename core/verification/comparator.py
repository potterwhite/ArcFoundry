import numpy as np
import onnxruntime as ort
from rknn.api import RKNN
from core.utils import logger
from typing import List, Dict, Any

class ModelComparator:
    """
    è´Ÿè´£å¯¹æ¯” ONNX åŽŸå§‹æ¨¡åž‹ä¸Ž RKNN æ¨¡æ‹Ÿå™¨çš„æŽ¨ç†ç²¾åº¦ã€‚
    ç”±äºŽ RV1126B ç­‰å¹³å°çš„ .rknn æ–‡ä»¶æ— æ³•åœ¨ PC æ¨¡æ‹Ÿè¿è¡Œï¼Œ
    æœ¬æ¨¡å—ä¼šæ‰§è¡Œ "Shadow Build" (å½±å­ç¼–è¯‘) æ¥å¯åŠ¨æ¨¡æ‹Ÿå™¨ã€‚
    """

    def __init__(self, target_platform: str):
        self.target_platform = target_platform
        self.rknn = RKNN(verbose=False)

    def prepare_simulator(self, onnx_path: str, input_shapes: List[List[int]], build_config: Dict[str, Any]):
        """
        åœ¨å†…å­˜ä¸­é‡æ–°ç¼–è¯‘æ¨¡åž‹ä»¥å¯åŠ¨æ¨¡æ‹Ÿå™¨ (Simulator Mode)
        """
        logger.info(f"[Verify] Initializing Simulator Environment for {self.target_platform}...")

        # 1. Config
        self.rknn.config(target_platform=self.target_platform)

        # 2. Load ONNX
        if self.rknn.load_onnx(model=onnx_path, input_size_list=input_shapes) != 0:
            raise RuntimeError("Simulator: Load ONNX failed!")

        # 3. Build (Shadow Build)
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ç»§æ‰¿ä¸»æµç¨‹çš„ build é…ç½®ï¼ˆå¦‚é‡åŒ–å‚æ•°ï¼‰ï¼Œç¡®ä¿æ¨¡æ‹Ÿçš„ä¸€è‡´æ€§
        # ä½†æˆ‘ä»¬å¼ºåˆ¶ do_quantization=False æ¥éªŒè¯ FP16 åŸºçº¿ï¼Œæˆ–è€…æ ¹æ® build_config å†³å®š
        # V1.1 é˜¶æ®µæˆ‘ä»¬å…ˆéªŒè¯ FP16 è¿žé€šæ€§
        ret = self.rknn.build(
            do_quantization=build_config.get('quantization', {}).get('enabled', False),
            dataset=build_config.get('quantization', {}).get('dataset', None)
        )
        if ret != 0:
            raise RuntimeError("Simulator: Build failed!")

        # 4. Init Runtime (target=None è§¦å‘æ¨¡æ‹Ÿå™¨æ¨¡å¼)
        if self.rknn.init_runtime(target=None) != 0:
            raise RuntimeError("Simulator: Init Runtime failed! (Is rknn-toolkit2 installed correctly?)")

        logger.info("[Verify] Simulator Ready.")

    def compare_with_onnx(self, onnx_path: str, inputs: Dict[str, np.ndarray]) -> Dict[str, float]:
        """
        æ‰§è¡ŒåŒè½¨æŽ¨ç†å¹¶è®¡ç®—ç›¸ä¼¼åº¦ã€‚
        """
        # 1. ONNX Inference
        logger.info("[Verify] Running Baseline ONNX Inference...")
        sess = ort.InferenceSession(onnx_path)
        onnx_input_names = [i.name for i in sess.get_inputs()]
        onnx_feed = {name: inputs[name] for name in onnx_input_names if name in inputs}
        onnx_outputs = sess.run(None, onnx_feed)

        # 2. RKNN Inference
        # Simulator æŽ¥æ”¶åˆ—è¡¨è¾“å…¥ï¼Œé¡ºåºéœ€ä¸Ž load_onnx æ—¶ä¸€è‡´
        rknn_feed_list = [inputs[name] for name in onnx_input_names]

        logger.info("[Verify] Running RKNN Simulator Inference...")
        rknn_outputs = self.rknn.inference(inputs=rknn_feed_list, data_format='nchw')

        # 3. Compute Metrics
        metrics = {}
        onnx_output_names = [o.name for o in sess.get_outputs()]

        # é˜²æ­¢è¾“å‡ºæ•°é‡ä¸ä¸€è‡´å´©æºƒ
        min_len = min(len(onnx_outputs), len(rknn_outputs))

        for idx in range(min_len):
            name = onnx_output_names[idx]
            out_onnx = onnx_outputs[idx].flatten()
            out_rknn = rknn_outputs[idx].flatten()

            # å¤„ç† NaN/Inf
            if not np.isfinite(out_onnx).all() or not np.isfinite(out_rknn).all():
                logger.warning(f"[Verify] Output '{name}' contains NaN/Inf!")
                metrics[name] = 0.0
                continue

            # Cosine Similarity
            dot_product = np.dot(out_onnx, out_rknn)
            norm_a = np.linalg.norm(out_onnx)
            norm_b = np.linalg.norm(out_rknn)

            if norm_a == 0 or norm_b == 0:
                # å‘é‡ä¸º0ï¼Œè§†ä¸ºå®Œå…¨ä¸€è‡´(1.0)æˆ–å®Œå…¨ä¸¢å¤±(0.0)ï¼Œè§†ä¸šåŠ¡è€Œå®šï¼Œè¿™é‡Œåä¿å®ˆç»™ 1.0 å¦‚æžœéƒ½ä¸º0
                cos_sim = 1.0 if norm_a == norm_b else 0.0
            else:
                cos_sim = dot_product / (norm_a * norm_b)

            metrics[name] = cos_sim
            logger.info(f"   ðŸ“Š Metric: Output '{name}' Cosine Similarity = {cos_sim:.6f}")

        self.rknn.release()
        return metrics

    @staticmethod
    def validate_metric(metrics: Dict[str, float], threshold=0.98) -> bool:
        all_pass = True
        for name, score in metrics.items():
            if score < threshold:
                all_pass = False
        return all_pass